---
title: "Chapter_6_7"
author: "Danielle A Presgraves"
date: "9/17/2019"
output:
  word_document: default
  pdf_document: default
---
### Normal distribution and t tests
## What we will do today: 
1. Online simulations of the normal distribution to get a sense of what it looks like and its properties. Data points that are normally distributed are a fundamental assumptions of many statistical tests (although some of the popular tests can allow for large violations in this assumption) so it is useful to get a 'sense' of what normal-ish data look like!

2. Investigating normality:

We care about whether or not our variable has a normal distribution because many of our parametric tests depend on the validity of that assumption. In fact, once we confirm how to assess normality, we'll look at the * t distribution and t test* which requires normality (although we'll also examine their robustness to violations of this assumption). In order to refine our understanding of normal assessment, we are going to simulate two distributions: one distribution will be normal and the other distribution will be Poisson (which is definitely NOT normal; see here: https://en.wikipedia.org/wiki/Poisson_distribution). We can compare the results of the various assessments and see how they handle normal versus non-normal data. 

  A. Visual assessment: histograms (maybe boxplots, too), *Q-Q plots* 
  
From your *R Book*: 

**"A Q-Q plot (which stands for Quantile-Quantile plot) compares any two distributions by plotting their quantiles against each other; if the two distributions are similar, the comparison points should result in a straight line through y=x. If the two distributions are not the same but are related in a linear manner then they should lie on a different line. A __normal quantile plot__ is a cumulative frequency plot that has a Y axis scaled so that a normal distribution will appear as a straight, diagonal line. A Normal Q-Q plot works in the same way but it compares the distribution of your data to a general normal distribution. This means that if your data is normally distributed (or close), than the two distributions are equal and so the plotted points should lie on a straight line. These curves are useful in assessing how and where a non-normal distribution differs from the
ideal."**
  
  B. Formal tests of normality - we'll leave Shapiro-wilks test of normality to Chapter 8 rather than trying to cram it into this module. 
 
3. * t test* 

A. t distribution

B. Examples of  one sample, two sample and paired t tests 

We will start by simulating a normal and a non-normal distribution so we can compare them: 
```{r}
#similiar to the dbinom(), pbinom(), qbinom(), and rbinom() but for the normal distribution
# and the Poisson distribution:
# normal distribution with 100 observations, mean of 1 and standard deviation of 1
norm_1<-rnorm(100,1,1)
# we can visualize this with a histogram
hist(norm_1,main="Normal distr'n with mean=1 and sd=1")
# Poisson distribution with lamda = 1
pois_1<-rpois(100,1)
# the histograms of these two distributions should convince you that these two
# distributions
# are VERY different
hist(pois_1,main="Poisson distr'n with lamda = 1")
```
If we didn't happen to know that one variable (norm_1) was from a normal distribution and the second variable (pois_1) was from a Poisson distribution, we could test them by creating a *normal quantile plot* followed by a line that plots the theoretical quantiles from a normal distribution that had the same mean and sd as the variable that you provide it with.

The initial visual results give us a sense of whether or not we need to transform the data or apply a non-parametric alternative to our parametric tests.
```{r}
# qqnorm plot
qqnorm(norm_1, main="How far away from a normal 
       distribution if our norm_1 distribtion?", col="Blue")
# qqline on top of the qqnorm
qqline(norm_1, col="Dark Blue")
qqnorm(pois_1, main="How far away from a normal distribution
       if our pois_1 distribution?", col="Orange")
# qqline on top of the qqnorm
qqline(pois_1,col="Red")
```
Note that we can also do this in ggplot2 (prettier but not necessary) with built in function, stat_qq() and stat_qq_line(). In order to keep ggplot consistent, you can also use the same functions but in 'geom' name format: geom_qq() and geom_qq_line(). You can see this done here:  
https://ggplot2.tidyverse.org/reference/geom_qq.html

```{r}
#call library so that we can knit the document together later!
library(ggplot2)
#re-simulate our normal distribution as a dataframe first since ggplot2 requires dataframes!
# notice that it has the same number of samples, and the same mean and sd as rnorm_1 variable used throughout the rest of this rmd file. 
dummyf <- data.frame(y = rnorm(100,1,1))
ggplot(dummyf, aes(sample = y))+ stat_qq() + stat_qq_line()
```
As an additional tangent (I am undisciplined with information that I hope you find useful!), although the qqnorm() is most often used due to the assumption of normality that most parametric tests require, you can also compare two distributions to see if they are from the same underlying distribution (basically to determine if they are the same or not) by using a slightly different Q-Q function called qqplot(). For instance, if we had two distributions and we knew that one of them followed a Poisson distribution with particular parameters, we could use qqplot(distr_1,known_poisson_distr) and see if a straight-ish line was produced. We don't use this function as much simply because, as mentioned, most of the time what we really need to know is if our sample follows a normal distribution.

Now, we move on to quantitative tests of normality. 

*t tests!* are used to test if a population mean is equal to a particular value (one sample t test), to the mean of a different population (two sample t test) or if the difference between two means is equal to a particular value. All three of these tests use the same R command but they take different arguments in the same function. We will start with the one sample t test:
$Ho: \mu_{moose}= 423 kg$
$Ha: \mu_{moose} \neq 423 kg$ 

```{r}
# one sample t tests: moose example
# statistical test is the one sampel t test: 
weights_moose<-c(401,380,393,450,420,435,426,397,415)
# with only n=9, we don't expect our histogram to give us much information
hist(weights_moose)
# we could also use the density function
plot(density(weights_moose), main="Moose Weights")
# it is mound shaped so it is likely okay. We could do further testing with
# qqnorm and qqline plots
qqnorm(weights_moose)
qqline(weights_moose)
mean(weights_moose)
# there don't appear to be any serious violations so let's continue with the t test
moose.t<-t.test(weights_moose,mu=423,var.equal=TRUE)
moose.t
#var.equal=TRUE isn't a required argument for one sample t-tests because, well, 
# there's only one sample so there are not two samples to compare variance. I am 
# just pointing out that this argument exists since you will need it for two sample
# t-tests. An additional argument that is part of the t.test() is one that specifies
# whether or not the t test is a one sided or two sided test. That argument can
# be one of three things: 
# alternative = c("two.sided", "less", "greater")
# If we want to use the alternate hypothesis that the mean of our sample of
# moose is less than the mean of 
# the moose population, mu=423, we would use the following command: 
moose_one_sided.t<-t.test(weights_moose,mu=423,alternative = "less")
moose_one_sided.t
```

Moving on to the *two sample t test*: six individuals are given a treatment and 6 are given a placebo and we want to test whether or not there is a true difference between them: 
$H_o: \mu_1 - \mu_2 = 0$
$H_A: \mu_1 - \mu_2 \neq 0$

```{r}
Drug<-c(101,11,103,93,99,104)
Placebo<-c(91,87,99.77,88,91)
# we should test these variables to see if they are both from normal distributions
# Remember the par function that allows you to, for instance, put both graphs into 
# one window
par(mfrow=c(1,2))
# density function
plot(density(Drug), main="Drug")
plot(density(Placebo), main="Placebo")
# good old boxplot to get an instant visual of the median and variation
boxplot(Drug,Placebo,ylab="reaction times to stimulus",names=c("Drug","Placebo"))
# compare the means of the Drug and Placebo groups
means<-c(mean(Drug),mean(Placebo))
means
# overlay the means onto the last graph plotted - in this case the boxplot - with
# the points function. Boxplots show medians but not means so we are just adding
# the means to this plot.  
points(means,col="Red",pch=15)
# stand deviations comparison
Drug_sd<-sd(Drug)
Drug_sd
sd(Placebo)
# these are not even close to normally distributed and they variances are 
# not even close to equal BUT they do have similar shapes (bi-modal) so it 
# might be okay to use the t test (kinda amazing how robust it can be, no?)
drug_treatment.t<-t.test(Drug,Placebo,var.equal=TRUE)
drug_treatment.t
# when stand deviations are really different, we need to use a welch's 
# approximate t-test and here we are comparing the results from welsh to the
# results from a regular t test. 
drug_treatment.t_welsh<-t.test(Drug,Placebo)
drug_treatment.t_welsh
```
Lastly, the paired t test also uses the t.test function but with the argument paired=TRUE (the default argument is FALSE). Do cars get better gas mileage when they are filled with premium gas versus when they are filled with regular gas? We can't use the regular t test because the assumption of the independence of data points is violated since we are testing each car twice (with regular gas and with premium gas) which means that by specifying the argument paired=TRUE in the t.test(), **R** modifies the $\alpha$ so that it doesn't become inflated. 
$H_o: \mu_{premium} - \mu_{regular} = 0$
$H_A: \mu_{premium} - \mu_{regular} \neq 0$
```{r}
Regular<-c(16,20,21,22,23,22,27,25,27,28)
Premium<-c(19,22,24,24,25,25,26,26,28,32)
# by setting paired to be TRUE, you get a paired t-test instead of a t-test. 
gas.t<-t.test(Regular, Premium,paired = TRUE)
gas.t
```
### Power of the t test! 
We can use this to determine the $n_{i}$ that we need for each group we are testing in a two sample t-test or the $n$ in a paired t test. The usual trade off is that to pick up a smaller true difference between two means, we have to use a lot more data. How much more data? Well, that will depend on the difference that we want to detect. For instance, to pick up a difference of 0.2 between the gas mileage with premium versus regular gas, what *n* would need for our paired t test to give us a power of 0.9? We have to input the sd that we are using: 

** Remember that the variances for the different t tests (one sample, two sample, welch's approx and paired) are all calculated slightly differently. You must use the correct stand deviation or, as you can see with the examples below, you will get incorrect results!**

```{r}
# calculate the sd of the data set where Regular-Premium since we are
# trying to test the difference between the two fuels
sd_paired_gas<-sd(Regular-Premium)
sd_paired_gas
# pair is defined
test_pair<-Regular-Premium
test_pair
# let's see if the differences between Regular-Premium are normally distributed
# since that is the assumption of the paired t-test
hist(test_pair)
# run the power t test with the appropriate sd
power.t.test(delta=0.2,sd=sd_paired_gas,type="paired",power=0.9)
# how does this compare to if you forget to use the appropriate sd and 
# just use the default value of 1?
power.t.test(delta=0.2,type="paired",power=0.9)
```
Let's see what happens with a power test for a two sample t test: 

First we need to calculate the pooled sd (or we can test to see if the variances are exactly the same). As in the case above, we compare the calculations for n under the circumstance where we use the correct sd value and under the default argument of the function to see how wildly different the results are! 

```{r}
# sd: 
Drug_sd<-sd(Drug)
Drug_sd
Placebo_sd<-sd(Placebo)
Placebo_sd
# pooled sd when each group has n=6. We do this by hand. There might be an easier 
# built-in way to do it but I haven't found it. If you do, as always, let me know!
pooled_sd_drugs<-sqrt((5*(Drug_sd^2)+5*(Placebo_sd^2))/(10))
pooled_sd_drugs
# run the power t test with the appropriate sd
power.t.test(delta=2,sd=pooled_sd_drugs,power=0.9)
# how does this compare to if you forget to use the appropriate sd 
# and just use the default value of 1?
power.t.test(delta=2,power=0.9)
```
### non-parametric alternative to the t test - we will look at that in chapter 8
